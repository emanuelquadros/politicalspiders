{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, \\\n",
    "                                    GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel, RFECV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import tree\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Loading and concatenating datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.4 s, sys: 148 ms, total: 1.55 s\n",
      "Wall time: 1.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "institutoliberal = pd.read_csv('datasets/institutoliberal.tsv',\n",
    "                               sep='\\t', index_col=0)\n",
    "mercadopopular = pd.read_csv('datasets/mercadopopular.tsv',\n",
    "                             sep='\\t', index_col=0)\n",
    "psol = pd.read_csv('datasets/solidariedadesocialista.tsv',\n",
    "                   sep='\\t', index_col=0)\n",
    "tijolaco = pd.read_csv('datasets/tijolaco.tsv', sep='\\t', index_col=0)\n",
    "ocafezinho = pd.read_csv('datasets/ocafezinho.tsv', sep='\\t', index_col=0)\n",
    "midiasemmascara = pd.read_csv('datasets/midiasemmascara.tsv',\n",
    "                sep='\\t', index_col=0)\n",
    "\n",
    "poldata = pd.concat((institutoliberal, mercadopopular,\n",
    "                     psol, tijolaco, ocafezinho, midiasemmascara),\n",
    "                    ignore_index=True)\n",
    "\n",
    "poldata = poldata[poldata['body'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# token count\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "def getLen(text):\n",
    "    nonPunct = re.compile('.*[A-Za-z0-9].*')  # must contain a letter or digit\n",
    "    filtered = [w for w in text if nonPunct.match(w)]\n",
    "    return len(filtered)\n",
    "\n",
    "n_tokens = [getLen(text) for text in poldata.body]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We hold out 20% our data as test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "data_train, data_test, pol_train, pol_test = \\\n",
    "            train_test_split(poldata['body'], poldata['pol'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Creating bags of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.4 s, sys: 184 ms, total: 29.6 s\n",
      "Wall time: 29.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stopwords = ['cafezinho', 'http', 'which',\n",
    "             'il', 'he', 'we', 'dp', 'institute', 'instituto']\n",
    "vectorizer = CountVectorizer(analyzer = \"word\", max_features = 5000,\n",
    "                                      stop_words=stopwords)\n",
    "train_features = vectorizer.fit_transform(data_train)\n",
    "test_features = vectorizer.transform(data_test)\n",
    "pol_features = vectorizer.transform(poldata['body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We are using a random forest classifier with 100 estimators, and out-of-bag... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "arboles.fit(train_features, pol_train)\n",
    "vocab = vectorizer.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           feature  importance\n",
      "2784       liberal    0.018783\n",
      "974      comunista    0.007665\n",
      "4656      tradução    0.007602\n",
      "3632          pois    0.007454\n",
      "3240         notas    0.007328\n",
      "2783      liberais    0.006950\n",
      "3147         mídia    0.006864\n",
      "2407         idéia    0.006599\n",
      "4518           tal    0.006431\n",
      "2787     liberdade    0.006206\n",
      "2012          farc    0.006017\n",
      "1503         dilma    0.005970\n",
      "4408    socialismo    0.005794\n",
      "1838   esquerdista    0.005684\n",
      "3744    presidenta    0.005675\n",
      "2501    indivíduos    0.005396\n",
      "2500     indivíduo    0.004936\n",
      "2261         golpe    0.004586\n",
      "3478        países    0.004552\n",
      "2734          lava    0.004476\n",
      "1839  esquerdistas    0.004403\n",
      "1644       eduardo    0.004242\n",
      "4409    socialista    0.004146\n",
      "2646          jato    0.004054\n",
      "2819         livre    0.004049\n",
      "2258         globo    0.004022\n",
      "4581   terroristas    0.004006\n",
      "2462      impostos    0.003956\n",
      "1073   constantino    0.003950\n",
      "4261     salgueiro    0.003900\n",
      "...            ...         ...\n",
      "2380        humana    0.001955\n",
      "3109        muitos    0.001937\n",
      "4823       verdade    0.001870\n",
      "563          aécio    0.001782\n",
      "849       cidadãos    0.001777\n",
      "657         brasil    0.001737\n",
      "3955        quanto    0.001726\n",
      "734    capitalismo    0.001710\n",
      "4503        século    0.001689\n",
      "2785   liberalismo    0.001674\n",
      "3868   propriedade    0.001661\n",
      "4580    terrorista    0.001659\n",
      "2283       governo    0.001649\n",
      "3313         olavo    0.001636\n",
      "4614          toda    0.001625\n",
      "1849        estado    0.001615\n",
      "4342           ser    0.001594\n",
      "1433         dessa    0.001562\n",
      "3041    ministério    0.001547\n",
      "1436        desses    0.001454\n",
      "4224      rousseff    0.001451\n",
      "772         castro    0.001441\n",
      "2264      golpista    0.001436\n",
      "3290     ocidental    0.001429\n",
      "967          comum    0.001417\n",
      "2077         fidel    0.001410\n",
      "4816     venezuela    0.001395\n",
      "4618         todos    0.001390\n",
      "2680          juiz    0.001388\n",
      "3048         mises    0.001311\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "feat_import = pd.DataFrame(data = {\"feature\": vocab, \\\n",
    "                                   \"importance\": arboles.feature_importances_})\n",
    "print(feat_import.sort_values(by='importance', ascending=False)[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.93531501  0.93773373  0.93175019  0.93231114  0.92668786]\n",
      "Accuracy: 0.93 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "arboles = RandomForestClassifier(n_estimators=100, oob_score=True)\n",
    "cvmodel = make_pipeline(vectorizer, arboles)\n",
    "cvscores = cross_val_score(cvmodel, data_train, pol_train, cv=5)\n",
    "print(cvscores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cvscores.mean(), cvscores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.935377711294\n"
     ]
    }
   ],
   "source": [
    "arboles = arboles.fit(train_features, pol_train)\n",
    "result_arb = arboles.predict(test_features)\n",
    "print(np.sum(result_arb == pol_test)/len(result_arb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We want to plot how the OOB error evolves with the number of estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ensemble_clfs = [\n",
    "    (\"RandomForestClassifier, max_features='sqrt'\",\n",
    "        RandomForestClassifier(warm_start=True, oob_score=True,\n",
    "                               max_features=\"sqrt\", n_jobs=-1)),\n",
    "    (\"RandomForestClassifier, max_features='log2'\",\n",
    "        RandomForestClassifier(warm_start=True, max_features='log2',\n",
    "                               oob_score=True, n_jobs=-1)),\n",
    "    (\"RandomForestClassifier, max_features=None\",\n",
    "        RandomForestClassifier(warm_start=True, max_features=None,\n",
    "                               oob_score=True, n_jobs=-1))\n",
    "]\n",
    "\n",
    "# Mapping a classifier name to a list of (<n_estimators>, <error rate>) pairs.\n",
    "error_rate = OrderedDict((label, []) for label, _ in ensemble_clfs)\n",
    "\n",
    "# Range of `n_estimators` values to explore.\n",
    "min_estimators = 15\n",
    "max_estimators = 175\n",
    "\n",
    "for label, clf in ensemble_clfs:\n",
    "    for i in range(min_estimators, max_estimators + 1):\n",
    "        clf.set_params(n_estimators=i)\n",
    "        clf.fit(important_polfeatures, poldata['pol'])\n",
    "\n",
    "        # Record the OOB error for each `n_estimators=i` setting.\n",
    "        oob_error = 1 - clf.oob_score_\n",
    "        error_rate[label].append((i, oob_error))\n",
    "\n",
    "# Generate the \"OOB error rate\" vs. \"n_estimators\" plot.\n",
    "for label, clf_err in error_rate.items():\n",
    "    xs, ys = zip(*clf_err)\n",
    "    plt.plot(xs, ys, label=label)\n",
    "\n",
    "plt.xlim(min_estimators, max_estimators)\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"OOB error rate\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig('oob_important', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "A multinominal naive bayes classifier performs worse on this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.88913816  0.8921092   0.89846672  0.8894914   0.8973256 ]\n",
      "Accuracy: 0.89 (+/- 0.01)\n",
      "CPU times: user 1min 5s, sys: 436 ms, total: 1min 5s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nb = MultinomialNB()\n",
    "\n",
    "cvmodel_nb = make_pipeline(vectorizer, nb)\n",
    "cvscores_nb = cross_val_score(cvmodel_nb, data_train, pol_train, cv=5)\n",
    "\n",
    "print(cvscores_nb)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cvscores_nb.mean(), cvscores_nb.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.891697830965\n"
     ]
    }
   ],
   "source": [
    "nb = nb.fit(train_features, pol_train)\n",
    "result_nb = nb.predict(test_features)\n",
    "print(np.sum(result_nb == pol_test)/len(result_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Let's try to make a grid search for the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "sfm = SelectFromModel(arboles, threshold=0.001)\n",
    "\n",
    "# Train the selector\n",
    "sfm.fit(train_features, pol_train)\n",
    "\n",
    "sup = sfm.get_support(indices=True)\n",
    "print(len(sup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "for feat_index in sup:\n",
    "    print(vocab[feat_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2014', '2016', 'aborto', 'americano', 'artigo', 'autor', 'aécio', 'bem', 'blog', 'brasil', 'brasileira', 'bush', 'capitalismo', 'castro', 'chávez', 'cidadãos', 'comunismo', 'comunista', 'comunistas', 'constantino', 'consumidores', 'crianças', 'cristã', 'cristãos', 'cuba', 'cultural', 'cunha', 'dessa', 'desse', 'desses', 'dilma', 'economia', 'eduardo', 'esquerda', 'esquerdista', 'esquerdistas', 'estado', 'farc', 'fato', 'federal', 'feira', 'fidel', 'folha', 'foto', 'gay', 'george', 'globo', 'golpe', 'golpista', 'governo', 'graça', 'homens', 'ideologia', 'idéia', 'idéias', 'igreja', 'imagem', 'impeachment', 'impostos', 'imprensa', 'individual', 'indivíduo', 'indivíduos', 'intelectual', 'jato', 'juiz', 'lava', 'liberais', 'liberal', 'liberalismo', 'liberdade', 'livre', 'livro', 'marxismo', 'marxista', 'menos', 'michel', 'ministério', 'mises', 'modo', 'moral', 'moro', 'muitos', 'mídia', 'nação', 'notas', 'ocidental', 'olavo', 'org', 'outros', 'países', 'pessoas', 'pois', 'porque', 'presidenta', 'presidente', 'privada', 'processo', 'produtividade', 'propriedade', 'prosperidade', 'psdb', 'publicado', 'quanto', 'realidade', 'realmente', 'religião', 'revolucionária', 'revolucionários', 'revolução', 'rousseff', 'salgueiro', 'sempre', 'ser', 'sobre', 'socialismo', 'socialista', 'socialistas', 'sociedade', 'soviética', 'stf', 'supremo', 'século', 'tais', 'tal', 'temer', 'terroristas', 'the', 'toda', 'todos', 'tradução', 'vai', 'venezuela', 'verdade', 'vida', 'vítimas', 'www']\n"
     ]
    }
   ],
   "source": [
    "imp_tokens = [vocab[feat_index] for feat_index in sup]\n",
    "print(imp_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Subset with most important features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "important_polfeatures = sfm.transform(pol_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.93400636  0.93362004  0.93474196  0.9315632   0.9251917 ]\n",
      "Accuracy: 0.93 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "important_train = sfm.transform(train_features)\n",
    "important_test = sfm.transform(test_features)\n",
    "# Create a new random forest classifier for the most important features\n",
    "\n",
    "# Create a new random forest classifier for the most important features\n",
    "clf_important = RandomForestClassifier(n_estimators=128, n_jobs=-1)\n",
    "\n",
    "# Train the new classifier on the new dataset containing the most important features\n",
    "#clf_important.fit(important_train, pol_train)\n",
    "\n",
    "imp_cvmodel = make_pipeline(clf_important)\n",
    "imp_cvscores = cross_val_score(imp_cvmodel, important_train, pol_train, cv=5)\n",
    "print(imp_cvscores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (imp_cvscores.mean(), imp_cvscores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.935377711294\n",
      "0.934480179506\n"
     ]
    }
   ],
   "source": [
    "# Train the new classifier on the new dataset containing the most important features\n",
    "clf_important.fit(important_train, pol_train)\n",
    "\n",
    "# Apply The Full Featured Classifier To The Test Data\n",
    "y_important_pred = clf_important.predict(important_test)\n",
    "print(accuracy_score(pol_test, y_important_pred))\n",
    "\n",
    "y_pred = arboles.predict(test_features)\n",
    "print(accuracy_score(pol_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10088, 5000)\n"
     ]
    }
   ],
   "source": [
    "tf_transformer = TfidfTransformer().fit(train_features)\n",
    "tfidf_features = tf_transformer.transform(train_features)\n",
    "print(tfidf_features.shape)\n",
    "tfidf_features = tfidf_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(train_features.shape)\n",
    "train_features_array = train_features.toarray()\n",
    "dist = np.sum(train_features_array, axis=0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "counts = zip(vocab, dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2383641"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100, oob_score=True)\n",
    "forest = forest.fit( train_features, pol_train )\n",
    "test_features = vectorizer.transform(data_test)\n",
    "test_features = test_features.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Features sorted by their mean impurity decrease.\n",
    "\n",
    "Some words in this set are suspicious. I should try to run the model using them as stopwords: [il, institute, blog,, pois, desses, dessa, nesse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pydotplus\n",
    "atree = clf_important.estimators_[0].tree_\n",
    "dot_data = tree.export_graphviz(atree, max_depth=10, \\\n",
    "                                       out_file=None,\n",
    "                                       feature_names=imp_tokens,\n",
    "                                       class_names=['right', 'left'],\n",
    "                                       label=all,\n",
    "                                       filled=True,\n",
    "                                       proportion=True) \n",
    "graph = pydotplus.graph_from_dot_data(dot_data) \n",
    "graph.write_pdf(\"poltree.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  },
  "name": "political-bag-of-words.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
