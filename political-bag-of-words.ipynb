{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, \\\n",
    "                                    GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel, RFECV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import tree\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Loading and concatenating datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.4 s, sys: 148 ms, total: 1.55 s\n",
      "Wall time: 1.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "institutoliberal = pd.read_csv('datasets/institutoliberal.tsv',\n",
    "                               sep='\\t', index_col=0)\n",
    "mercadopopular = pd.read_csv('datasets/mercadopopular.tsv',\n",
    "                             sep='\\t', index_col=0)\n",
    "psol = pd.read_csv('datasets/solidariedadesocialista.tsv',\n",
    "                   sep='\\t', index_col=0)\n",
    "tijolaco = pd.read_csv('datasets/tijolaco.tsv', sep='\\t', index_col=0)\n",
    "ocafezinho = pd.read_csv('datasets/ocafezinho.tsv', sep='\\t', index_col=0)\n",
    "midiasemmascara = pd.read_csv('datasets/midiasemmascara.tsv',\n",
    "                sep='\\t', index_col=0)\n",
    "\n",
    "poldata = pd.concat((institutoliberal, mercadopopular,\n",
    "                     psol, tijolaco, ocafezinho, midiasemmascara),\n",
    "                    ignore_index=True)\n",
    "\n",
    "poldata = poldata[poldata['body'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'antes informar leitor sobre previsões 2017 ( parte final texto ), deixo aqui registrado modesto : sei irá ocorrer 2017 . é melhor previsão possível 2017 . defesa , afirmo qualquer bom economista mesma resposta . experiência , últimos 20 anos , nunca tão difícil prever acontecerá ano seguinte agora . tudo pode acontecer , pode acontecer . efeitos credibilidade , pode conferir previsões anteriores aqui : ) previsões 2016 ( feita 26 dezembro 2015 ) b ) previsões 2015 ( feita 5 dezembro 2014 ) c ) previsões 2014 ( feita 18 dezembro 2013 ) d ) previsões 2013 ( feita 12 dezembro 2012 ). peço atenção leitor passagem escrevi ainda 2012 elaborava previsões 2013 : “ governo insistir curso atual política econômica , partir 2015 , problema enfrentamos final década 1970 começo década 1980 : inflação alta , crescimento baixo desemprego alto . blog insiste repetir : caminho reviver década perdida , cometendo mesmos erros cometidos década 1970 geraram 30 anos baixo crescimento economia brasileira “. ) resumo algumas previsões gerais feitas blog desde 2009 ( escrito 5 dezembro 2013 ). agora vamos acredito deva ocorrer 2017 : pib : + 1 , 5 % ( , iremos crescer ano vem ) inflação : 5 , 5 % desemprego : continuará redor 12 % ( infelizmente desemprego continuará ser problema sério ) ibovespa : acho ano ruim bolsa . claro ações individuais podem ter destaque , índice todo deve ter desempenho similar inflação . mercado imobiliário : acho vai continuar patinando junho , daí diante acho estabiliza . contas públicas : ano horroroso contas públicas . próprio governo federal prevê déficit primário ordem r $ 139 , 5 bilhões . confesso , modesta opinião , tal déficit é sustentável . medidas adicionais ser tomadas . problema virá estados municípios . 2017 vez municípios pararem pagar salário funcionários ( acontece hoje diversos funcionários estaduais ). contas previdência diversos estados municípios impagáveis . 2017 ficará claro vez todas . campo externo maior ameaça brasil continua sendo aumento taxas juros americanas . sim pode complicar razoavelmente situação . sorte tais taxas ainda continuam patamar baixo , cedo tarde voltarão patamar normal . brasil precisa realizar urgentemente reformas econômicas antes taxas juros americanas retornem níveis históricos . verdade cruel é 2017 tudo pode acontecer , tudo pode acontecer …'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = poldata.body\n",
    "texts.ix[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "def getLen(text):\n",
    "    nonPunct = re.compile('.*[A-Za-z0-9].*')  # must contain a letter or digit\n",
    "    filtered = [w for w in text if nonPunct.match(w)]\n",
    "    return len(filtered)\n",
    "\n",
    "n_tokens = [getLen(text) for text in poldata.body]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94033684"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(n_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We hold out 20% our data as test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "data_train, data_test, pol_train, pol_test = \\\n",
    "            train_test_split(poldata['body'], poldata['pol'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Creating bags of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.4 s, sys: 184 ms, total: 29.6 s\n",
      "Wall time: 29.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stopwords = ['cafezinho', 'http', 'which',\n",
    "             'il', 'he', 'we', 'dp', 'institute', 'instituto']\n",
    "vectorizer = CountVectorizer(analyzer = \"word\", max_features = 5000,\n",
    "                                      stop_words=stopwords)\n",
    "train_features = vectorizer.fit_transform(data_train)\n",
    "test_features = vectorizer.transform(data_test)\n",
    "pol_features = vectorizer.transform(poldata['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "freqs = [(word, pol_features.getcol(idx).sum()) for word, idx\n",
    "                in vectorizer.vocabulary_.items()]\n",
    "print(sorted(freqs, key = lambda x: -x[1])[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We are using a random forest classifier with 100 estimators, and out-of-bag... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "arboles.fit(train_features, pol_train)\n",
    "vocab = vectorizer.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           feature  importance\n",
      "2784       liberal    0.018783\n",
      "974      comunista    0.007665\n",
      "4656      tradução    0.007602\n",
      "3632          pois    0.007454\n",
      "3240         notas    0.007328\n",
      "2783      liberais    0.006950\n",
      "3147         mídia    0.006864\n",
      "2407         idéia    0.006599\n",
      "4518           tal    0.006431\n",
      "2787     liberdade    0.006206\n",
      "2012          farc    0.006017\n",
      "1503         dilma    0.005970\n",
      "4408    socialismo    0.005794\n",
      "1838   esquerdista    0.005684\n",
      "3744    presidenta    0.005675\n",
      "2501    indivíduos    0.005396\n",
      "2500     indivíduo    0.004936\n",
      "2261         golpe    0.004586\n",
      "3478        países    0.004552\n",
      "2734          lava    0.004476\n",
      "1839  esquerdistas    0.004403\n",
      "1644       eduardo    0.004242\n",
      "4409    socialista    0.004146\n",
      "2646          jato    0.004054\n",
      "2819         livre    0.004049\n",
      "2258         globo    0.004022\n",
      "4581   terroristas    0.004006\n",
      "2462      impostos    0.003956\n",
      "1073   constantino    0.003950\n",
      "4261     salgueiro    0.003900\n",
      "...            ...         ...\n",
      "2380        humana    0.001955\n",
      "3109        muitos    0.001937\n",
      "4823       verdade    0.001870\n",
      "563          aécio    0.001782\n",
      "849       cidadãos    0.001777\n",
      "657         brasil    0.001737\n",
      "3955        quanto    0.001726\n",
      "734    capitalismo    0.001710\n",
      "4503        século    0.001689\n",
      "2785   liberalismo    0.001674\n",
      "3868   propriedade    0.001661\n",
      "4580    terrorista    0.001659\n",
      "2283       governo    0.001649\n",
      "3313         olavo    0.001636\n",
      "4614          toda    0.001625\n",
      "1849        estado    0.001615\n",
      "4342           ser    0.001594\n",
      "1433         dessa    0.001562\n",
      "3041    ministério    0.001547\n",
      "1436        desses    0.001454\n",
      "4224      rousseff    0.001451\n",
      "772         castro    0.001441\n",
      "2264      golpista    0.001436\n",
      "3290     ocidental    0.001429\n",
      "967          comum    0.001417\n",
      "2077         fidel    0.001410\n",
      "4816     venezuela    0.001395\n",
      "4618         todos    0.001390\n",
      "2680          juiz    0.001388\n",
      "3048         mises    0.001311\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "feat_import = pd.DataFrame(data = {\"feature\": vocab, \\\n",
    "                                   \"importance\": arboles.feature_importances_})\n",
    "print(feat_import.sort_values(by='importance', ascending=False)[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.93531501  0.93773373  0.93175019  0.93231114  0.92668786]\n",
      "Accuracy: 0.93 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "arboles = RandomForestClassifier(n_estimators=100, oob_score=True)\n",
    "cvmodel = make_pipeline(vectorizer, arboles)\n",
    "cvscores = cross_val_score(cvmodel, data_train, pol_train, cv=5)\n",
    "print(cvscores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cvscores.mean(), cvscores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.935377711294\n"
     ]
    }
   ],
   "source": [
    "arboles = arboles.fit(train_features, pol_train)\n",
    "result_arb = arboles.predict(test_features)\n",
    "print(np.sum(result_arb == pol_test)/len(result_arb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.91  0.09]\n",
      " [ 0.55  0.45]\n",
      " [ 1.    0.  ]\n",
      " ..., \n",
      " [ 0.87  0.13]\n",
      " [ 0.86  0.14]\n",
      " [ 0.99  0.01]]\n"
     ]
    }
   ],
   "source": [
    "arb_probs = arboles.predict_proba(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%reset -s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We want to plot how the OOB error evolves with the number of estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15min 37s, sys: 940 ms, total: 15min 38s\n",
      "Wall time: 15min 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ensemble_clfs = [\n",
    "    (\"RandomForestClassifier, max_features='sqrt'\",\n",
    "        RandomForestClassifier(warm_start=True, oob_score=True,\n",
    "                               max_features=\"sqrt\", n_jobs=-1)),\n",
    "    (\"RandomForestClassifier, max_features='log2'\",\n",
    "        RandomForestClassifier(warm_start=True, max_features='log2',\n",
    "                               oob_score=True, n_jobs=-1)),\n",
    "    (\"RandomForestClassifier, max_features=None\",\n",
    "        RandomForestClassifier(warm_start=True, max_features=None,\n",
    "                               oob_score=True, n_jobs=-1))\n",
    "]\n",
    "\n",
    "# Map a classifier name to a list of (<n_estimators>, <error rate>) pairs.\n",
    "error_rate = OrderedDict((label, []) for label, _ in ensemble_clfs)\n",
    "\n",
    "# Range of `n_estimators` values to explore.\n",
    "min_estimators = 15\n",
    "max_estimators = 175\n",
    "\n",
    "for label, clf in ensemble_clfs:\n",
    "    for i in range(min_estimators, max_estimators + 1):\n",
    "        clf.set_params(n_estimators=i)\n",
    "        clf.fit(important_polfeatures, poldata['pol'])\n",
    "\n",
    "        # Record the OOB error for each `n_estimators=i` setting.\n",
    "        oob_error = 1 - clf.oob_score_\n",
    "        error_rate[label].append((i, oob_error))\n",
    "\n",
    "# Generate the \"OOB error rate\" vs. \"n_estimators\" plot.\n",
    "for label, clf_err in error_rate.items():\n",
    "    xs, ys = zip(*clf_err)\n",
    "    plt.plot(xs, ys, label=label)\n",
    "\n",
    "plt.xlim(min_estimators, max_estimators)\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"OOB error rate\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig('oob_important', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "# Generate the \"OOB error rate\" vs. \"n_estimators\" plot.\n",
    "for label, clf_err in error_rate.items():\n",
    "    xs, ys = zip(*clf_err)\n",
    "    plt.plot(xs, ys, label=label)\n",
    "\n",
    "plt.xlim(min_estimators, max_estimators)\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"OOB error rate\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig('oob', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "A multinominal naive bayes classifier performs worse on this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.88913816  0.8921092   0.89846672  0.8894914   0.8973256 ]\n",
      "Accuracy: 0.89 (+/- 0.01)\n",
      "CPU times: user 1min 5s, sys: 436 ms, total: 1min 5s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nb = MultinomialNB()\n",
    "\n",
    "cvmodel_nb = make_pipeline(vectorizer, nb)\n",
    "cvscores_nb = cross_val_score(cvmodel_nb, data_train, pol_train, cv=5)\n",
    "\n",
    "print(cvscores_nb)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cvscores_nb.mean(), cvscores_nb.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.891697830965\n"
     ]
    }
   ],
   "source": [
    "nb = nb.fit(train_features, pol_train)\n",
    "result_nb = nb.predict(test_features)\n",
    "print(np.sum(result_nb == pol_test)/len(result_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Let's try to make a grid search for the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "sfm = SelectFromModel(arboles, threshold=0.001)\n",
    "\n",
    "# Train the selector\n",
    "sfm.fit(train_features, pol_train)\n",
    "\n",
    "sup = sfm.get_support(indices=True)\n",
    "print(len(sup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "for feat_index in sup:\n",
    "    print(vocab[feat_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2014', '2016', 'aborto', 'americano', 'artigo', 'autor', 'aécio', 'bem', 'blog', 'brasil', 'brasileira', 'bush', 'capitalismo', 'castro', 'chávez', 'cidadãos', 'comunismo', 'comunista', 'comunistas', 'constantino', 'consumidores', 'crianças', 'cristã', 'cristãos', 'cuba', 'cultural', 'cunha', 'dessa', 'desse', 'desses', 'dilma', 'economia', 'eduardo', 'esquerda', 'esquerdista', 'esquerdistas', 'estado', 'farc', 'fato', 'federal', 'feira', 'fidel', 'folha', 'foto', 'gay', 'george', 'globo', 'golpe', 'golpista', 'governo', 'graça', 'homens', 'ideologia', 'idéia', 'idéias', 'igreja', 'imagem', 'impeachment', 'impostos', 'imprensa', 'individual', 'indivíduo', 'indivíduos', 'intelectual', 'jato', 'juiz', 'lava', 'liberais', 'liberal', 'liberalismo', 'liberdade', 'livre', 'livro', 'marxismo', 'marxista', 'menos', 'michel', 'ministério', 'mises', 'modo', 'moral', 'moro', 'muitos', 'mídia', 'nação', 'notas', 'ocidental', 'olavo', 'org', 'outros', 'países', 'pessoas', 'pois', 'porque', 'presidenta', 'presidente', 'privada', 'processo', 'produtividade', 'propriedade', 'prosperidade', 'psdb', 'publicado', 'quanto', 'realidade', 'realmente', 'religião', 'revolucionária', 'revolucionários', 'revolução', 'rousseff', 'salgueiro', 'sempre', 'ser', 'sobre', 'socialismo', 'socialista', 'socialistas', 'sociedade', 'soviética', 'stf', 'supremo', 'século', 'tais', 'tal', 'temer', 'terroristas', 'the', 'toda', 'todos', 'tradução', 'vai', 'venezuela', 'verdade', 'vida', 'vítimas', 'www']\n"
     ]
    }
   ],
   "source": [
    "imp_tokens = [vocab[feat_index] for feat_index in sup]\n",
    "print(imp_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imp_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Subset with most important features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "important_polfeatures = sfm.transform(pol_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.93400636  0.93362004  0.93474196  0.9315632   0.9251917 ]\n",
      "Accuracy: 0.93 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "important_train = sfm.transform(train_features)\n",
    "important_test = sfm.transform(test_features)\n",
    "# Create a new random forest classifier for the most important features\n",
    "\n",
    "# Create a new random forest classifier for the most important features\n",
    "clf_important = RandomForestClassifier(n_estimators=128, n_jobs=-1)\n",
    "\n",
    "# Train the new classifier on the new dataset containing the most important features\n",
    "#clf_important.fit(important_train, pol_train)\n",
    "\n",
    "imp_cvmodel = make_pipeline(clf_important)\n",
    "imp_cvscores = cross_val_score(imp_cvmodel, important_train, pol_train, cv=5)\n",
    "print(imp_cvscores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (imp_cvscores.mean(), imp_cvscores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.935377711294\n",
      "0.934480179506\n"
     ]
    }
   ],
   "source": [
    "# Train the new classifier on the new dataset containing the most important features\n",
    "clf_important.fit(important_train, pol_train)\n",
    "\n",
    "# Apply The Full Featured Classifier To The Test Data\n",
    "y_important_pred = clf_important.predict(important_test)\n",
    "print(accuracy_score(pol_test, y_important_pred))\n",
    "\n",
    "y_pred = arboles.predict(test_features)\n",
    "print(accuracy_score(pol_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10088, 5000)\n"
     ]
    }
   ],
   "source": [
    "tf_transformer = TfidfTransformer().fit(train_features)\n",
    "tfidf_features = tf_transformer.transform(train_features)\n",
    "print(tfidf_features.shape)\n",
    "tfidf_features = tfidf_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(train_features.shape)\n",
    "train_features_array = train_features.toarray()\n",
    "dist = np.sum(train_features_array, axis=0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "counts = zip(vocab, dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2383641"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100, oob_score=True)\n",
    "forest = forest.fit( train_features, pol_train )\n",
    "test_features = vectorizer.transform(data_test)\n",
    "test_features = test_features.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Features sorted by their mean impurity decrease.\n",
    "\n",
    "Some words in this set are suspicious. I should try to run the model using them as stopwords: [il, institute, blog,, pois, desses, dessa, nesse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-144-57883e71a391>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iris.dot\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m      \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tree' is not defined"
     ]
    }
   ],
   "source": [
    "with open(\"iris.dot\", 'w') as f:\n",
    "     f = tree.export_graphviz(atree, out_file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pydotplus\n",
    "atree = clf_important.estimators_[0].tree_\n",
    "dot_data = tree.export_graphviz(atree, max_depth=10, \\\n",
    "                                       out_file=None,\n",
    "                                       feature_names=imp_tokens,\n",
    "                                       class_names=['right', 'left'],\n",
    "                                       label=all,\n",
    "                                       filled=True,\n",
    "                                       proportion=True) \n",
    "graph = pydotplus.graph_from_dot_data(dot_data) \n",
    "graph.write_pdf(\"poltree.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'www'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[feat_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "forest2 = RandomForestClassifier(n_estimators=250, oob_score=True)\n",
    "forest2 = forest2.fit(train_features, pol_train)\n",
    "result2 = forest2.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92664551942902462"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest2.score(test_features, pol_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['left', 'right'], dtype=object)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest2.decision_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "The results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.867961934972\n"
     ]
    }
   ],
   "source": [
    "forest_tf = RandomForestClassifier(n_estimators=100, oob_score=True)\n",
    "forest_tf = forest_tf.fit(tfidf_features, pol_train)\n",
    "result_tf = forest_tf.predict(test_features)\n",
    "print(np.sum(result_tf == pol_test)/len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.911974623315\n",
      "0.919805709754\n",
      "0.913659793814\n"
     ]
    }
   ],
   "source": [
    "print(forest.oob_score_)\n",
    "print(forest2.oob_score_)\n",
    "print(forest_tf.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19107142857142856"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result[result == 'left'])/len(result[result == 'right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "clf = make_pipeline(vectorizer, SelectFromModel(LinearSVC()), RandomForestClassifier())\n",
    "clf.fit(poldata['body'], poldata['pol'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  },
  "name": "political-bag-of-words.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
